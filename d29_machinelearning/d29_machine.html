<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Machine Learning with R  ðŸ¤–</title>
    <meta charset="utf-8" />
    <meta name="author" content="S. Mason Garrison" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="../slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Introduction to Machine Learning with R<br> ðŸ¤–
]
.author[
### S. Mason Garrison
]

---


&lt;!-- https://github.com/Eclectikus/playingsonar/blob/master/InfoSonar.Rmd --&gt;




layout: true
  
&lt;div class="my-footer"&gt;
&lt;span&gt;
&lt;a href="https://DataScience4Psych.github.io/DataScience4Psych/" target="_blank"&gt;Data Science for Psychologists&lt;/a&gt;
&lt;/span&gt;
&lt;/div&gt; 

---



## Machine Learning `\(in\)` Data Science

.pull-left[
&lt;img src="img/ai_comparing_supervised.png" width="60%" style="display: block; margin: auto auto auto 0;" /&gt;
]

.pull-right[
- Machine Learning is a subset of data science focused on models and algorithms that allow computers to learn from and make decisions based on data.
- Three main types of machine learning:
  - Supervised learning: With labeled data
  - Unsupervised learning: Without labeled data
  - Reinforcement learning: Based on feedback from the environment
]

---

## Machine Learning vs. Traditional Statistics

- **Statistical Inference:** Focus on hypothesis testing, model assumptions.
- **Machine Learning:** Emphasis on prediction accuracy and model performance on unseen data.



---


## Dataset Overview

.pull-left[
&lt;img src="img/PhysicsSchemw.png" width="60%" style="display: block; margin: auto auto auto 0;" /&gt;
]

.pull-right[
Objective: Differentiate between Sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock.
Features: Signal strength across various frequencies.
]

---

## Load the Sonar Data

The Sonar data is a classic dataset for binary classification (Gorman and Sejnowski, 1988).

It contains 208 observations of sonar signals bounced off a metal cylinder and a roughly cylindrical rock. The 60 numerical variables are the strength of the returns at different frequencies. The final variable is the Class, which is a factor with two levels: "R" for rock and "M" for metal.

.note[Gorman, R. P., and Sejnowski, T. J. (1988). "Analysis of Hidden Units in a Layered Network Trained to Classify Sonar Targets" in Neural Networks, Vol. 1, [pp. 75-89](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.8959&amp;rep=rep1&amp;type=pdf). Same authors almost a year later published: [Learned Classification of Sonar Targets Using a Massively Parallel Network](https://papers.cnl.salk.edu/PDFs/Learned%20Classification%20of%20Sonar%20Targets%20Using%20a%20Massively%20Parallel%20Network%201988-3231.pdf)]



```
## Rows: 208
## Columns: 61
## $ V1    &lt;dbl&gt; 0.0200, 0.0453, 0.0262, 0.0100, 0.0762, 0.0286, 0â€¦
## $ V2    &lt;dbl&gt; 0.0371, 0.0523, 0.0582, 0.0171, 0.0666, 0.0453, 0â€¦
## $ V3    &lt;dbl&gt; 0.0428, 0.0843, 0.1099, 0.0623, 0.0481, 0.0277, 0â€¦
## $ V4    &lt;dbl&gt; 0.0207, 0.0689, 0.1083, 0.0205, 0.0394, 0.0174, 0â€¦
## $ V5    &lt;dbl&gt; 0.0954, 0.1183, 0.0974, 0.0205, 0.0590, 0.0384, 0â€¦
## $ V6    &lt;dbl&gt; 0.0986, 0.2583, 0.2280, 0.0368, 0.0649, 0.0990, 0â€¦
## $ V7    &lt;dbl&gt; 0.1539, 0.2156, 0.2431, 0.1098, 0.1209, 0.1201, 0â€¦
## $ V8    &lt;dbl&gt; 0.1601, 0.3481, 0.3771, 0.1276, 0.2467, 0.1833, 0â€¦
## $ V9    &lt;dbl&gt; 0.3109, 0.3337, 0.5598, 0.0598, 0.3564, 0.2105, 0â€¦
## $ V10   &lt;dbl&gt; 0.2111, 0.2872, 0.6194, 0.1264, 0.4459, 0.3039, 0â€¦
## $ V11   &lt;dbl&gt; 0.1609, 0.4918, 0.6333, 0.0881, 0.4152, 0.2988, 0â€¦
## $ V12   &lt;dbl&gt; 0.1582, 0.6552, 0.7060, 0.1992, 0.3952, 0.4250, 0â€¦
## $ V13   &lt;dbl&gt; 0.2238, 0.6919, 0.5544, 0.0184, 0.4256, 0.6343, 0â€¦
## $ V14   &lt;dbl&gt; 0.0645, 0.7797, 0.5320, 0.2261, 0.4135, 0.8198, 0â€¦
## $ V15   &lt;dbl&gt; 0.0660, 0.7464, 0.6479, 0.1729, 0.4528, 1.0000, 0â€¦
## $ V16   &lt;dbl&gt; 0.2273, 0.9444, 0.6931, 0.2131, 0.5326, 0.9988, 0â€¦
## $ V17   &lt;dbl&gt; 0.3100, 1.0000, 0.6759, 0.0693, 0.7306, 0.9508, 0â€¦
## $ V18   &lt;dbl&gt; 0.2999, 0.8874, 0.7551, 0.2281, 0.6193, 0.9025, 0â€¦
## $ V19   &lt;dbl&gt; 0.5078, 0.8024, 0.8929, 0.4060, 0.2032, 0.7234, 0â€¦
## $ V20   &lt;dbl&gt; 0.4797, 0.7818, 0.8619, 0.3973, 0.4636, 0.5122, 0â€¦
## $ V21   &lt;dbl&gt; 0.5783, 0.5212, 0.7974, 0.2741, 0.4148, 0.2074, 0â€¦
## $ V22   &lt;dbl&gt; 0.5071, 0.4052, 0.6737, 0.3690, 0.4292, 0.3985, 0â€¦
## $ V23   &lt;dbl&gt; 0.4328, 0.3957, 0.4293, 0.5556, 0.5730, 0.5890, 0â€¦
## $ V24   &lt;dbl&gt; 0.5550, 0.3914, 0.3648, 0.4846, 0.5399, 0.2872, 0â€¦
## $ V25   &lt;dbl&gt; 0.6711, 0.3250, 0.5331, 0.3140, 0.3161, 0.2043, 0â€¦
## $ V26   &lt;dbl&gt; 0.6415, 0.3200, 0.2413, 0.5334, 0.2285, 0.5782, 0â€¦
## $ V27   &lt;dbl&gt; 0.7104, 0.3271, 0.5070, 0.5256, 0.6995, 0.5389, 0â€¦
## $ V28   &lt;dbl&gt; 0.8080, 0.2767, 0.8533, 0.2520, 1.0000, 0.3750, 0â€¦
## $ V29   &lt;dbl&gt; 0.6791, 0.4423, 0.6036, 0.2090, 0.7262, 0.3411, 0â€¦
## $ V30   &lt;dbl&gt; 0.3857, 0.2028, 0.8514, 0.3559, 0.4724, 0.5067, 0â€¦
## $ V31   &lt;dbl&gt; 0.1307, 0.3788, 0.8512, 0.6260, 0.5103, 0.5580, 0â€¦
## $ V32   &lt;dbl&gt; 0.2604, 0.2947, 0.5045, 0.7340, 0.5459, 0.4778, 0â€¦
## $ V33   &lt;dbl&gt; 0.5121, 0.1984, 0.1862, 0.6120, 0.2881, 0.3299, 0â€¦
## $ V34   &lt;dbl&gt; 0.7547, 0.2341, 0.2709, 0.3497, 0.0981, 0.2198, 0â€¦
## $ V35   &lt;dbl&gt; 0.8537, 0.1306, 0.4232, 0.3953, 0.1951, 0.1407, 0â€¦
## $ V36   &lt;dbl&gt; 0.8507, 0.4182, 0.3043, 0.3012, 0.4181, 0.2856, 0â€¦
## $ V37   &lt;dbl&gt; 0.6692, 0.3835, 0.6116, 0.5408, 0.4604, 0.3807, 0â€¦
## $ V38   &lt;dbl&gt; 0.6097, 0.1057, 0.6756, 0.8814, 0.3217, 0.4158, 0â€¦
## $ V39   &lt;dbl&gt; 0.4943, 0.1840, 0.5375, 0.9857, 0.2828, 0.4054, 0â€¦
## $ V40   &lt;dbl&gt; 0.2744, 0.1970, 0.4719, 0.9167, 0.2430, 0.3296, 0â€¦
## $ V41   &lt;dbl&gt; 0.0510, 0.1674, 0.4647, 0.6121, 0.1979, 0.2707, 0â€¦
## $ V42   &lt;dbl&gt; 0.2834, 0.0583, 0.2587, 0.5006, 0.2444, 0.2650, 0â€¦
## $ V43   &lt;dbl&gt; 0.2825, 0.1401, 0.2129, 0.3210, 0.1847, 0.0723, 0â€¦
## $ V44   &lt;dbl&gt; 0.4256, 0.1628, 0.2222, 0.3202, 0.0841, 0.1238, 0â€¦
## $ V45   &lt;dbl&gt; 0.2641, 0.0621, 0.2111, 0.4295, 0.0692, 0.1192, 0â€¦
## $ V46   &lt;dbl&gt; 0.1386, 0.0203, 0.0176, 0.3654, 0.0528, 0.1089, 0â€¦
## $ V47   &lt;dbl&gt; 0.1051, 0.0530, 0.1348, 0.2655, 0.0357, 0.0623, 0â€¦
## $ V48   &lt;dbl&gt; 0.1343, 0.0742, 0.0744, 0.1576, 0.0085, 0.0494, 0â€¦
## $ V49   &lt;dbl&gt; 0.0383, 0.0409, 0.0130, 0.0681, 0.0230, 0.0264, 0â€¦
## $ V50   &lt;dbl&gt; 0.0324, 0.0061, 0.0106, 0.0294, 0.0046, 0.0081, 0â€¦
## $ V51   &lt;dbl&gt; 0.0232, 0.0125, 0.0033, 0.0241, 0.0156, 0.0104, 0â€¦
## $ V52   &lt;dbl&gt; 0.0027, 0.0084, 0.0232, 0.0121, 0.0031, 0.0045, 0â€¦
## $ V53   &lt;dbl&gt; 0.0065, 0.0089, 0.0166, 0.0036, 0.0054, 0.0014, 0â€¦
## $ V54   &lt;dbl&gt; 0.0159, 0.0048, 0.0095, 0.0150, 0.0105, 0.0038, 0â€¦
## $ V55   &lt;dbl&gt; 0.0072, 0.0094, 0.0180, 0.0085, 0.0110, 0.0013, 0â€¦
## $ V56   &lt;dbl&gt; 0.0167, 0.0191, 0.0244, 0.0073, 0.0015, 0.0089, 0â€¦
## $ V57   &lt;dbl&gt; 0.0180, 0.0140, 0.0316, 0.0050, 0.0072, 0.0057, 0â€¦
## $ V58   &lt;dbl&gt; 0.0084, 0.0049, 0.0164, 0.0044, 0.0048, 0.0027, 0â€¦
## $ V59   &lt;dbl&gt; 0.0090, 0.0052, 0.0095, 0.0040, 0.0107, 0.0051, 0â€¦
## $ V60   &lt;dbl&gt; 0.0032, 0.0044, 0.0078, 0.0117, 0.0094, 0.0062, 0â€¦
## $ Class &lt;fct&gt; R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, Râ€¦
```

---

## Preprocessing for Machine Learning



---

## Building a Model


```r
# Building a model using caret
# For this example, we'll use a simple linear discriminant analysis (LDA) model
set.seed(123)
fitControl &lt;- trainControl(method = "cv", number = 10) # 10-fold cross-validation

modelLDA &lt;- train(Class ~ ., data=trainDataPreprocessed, method="lda", trControl=fitControl)

# Display the model's details
print(modelLDA)
```

```
## Linear Discriminant Analysis 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.7070833  0.4112511
```

---

## Evaluating Model Performance


```r
# Predicting on the test dataset
predictions &lt;- predict(modelLDA, testDataPreprocessed)

# Model performance
confusionMatrix(predictions, testDataPreprocessed$Class)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  M  R
##          M 20  8
##          R  7 16
##                                           
##                Accuracy : 0.7059          
##                  95% CI : (0.5617, 0.8251)
##     No Information Rate : 0.5294          
##     P-Value [Acc &gt; NIR] : 0.007812        
##                                           
##                   Kappa : 0.4084          
##                                           
##  Mcnemar's Test P-Value : 1.000000        
##                                           
##             Sensitivity : 0.7407          
##             Specificity : 0.6667          
##          Pos Pred Value : 0.7143          
##          Neg Pred Value : 0.6957          
##              Prevalence : 0.5294          
##          Detection Rate : 0.3922          
##    Detection Prevalence : 0.5490          
##       Balanced Accuracy : 0.7037          
##                                           
##        'Positive' Class : M               
## 
```


```r
ggplot(trainDataPreprocessed, aes(x=V1, fill=Class)) + 
    geom_density(alpha=0.5) +
    labs(title="Density Plot of Feature V1 by Class", x="Feature V1", y="Density")
```

&lt;img src="d29_machine_files/figure-html/unnamed-chunk-6-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---


Understanding confusion matrix.
Metrics: Accuracy, Precision, Recall


---
# Sources

- [Eclectikus](https://github.com/Eclectikus)'s Playing with Sonar ([link](https://github.com/Eclectikus/playingsonar))

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightLines": true,
"highlightStyle": "solarized-light",
"countIncrementalSlides": false,
"slideNumberFormat": ""
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
