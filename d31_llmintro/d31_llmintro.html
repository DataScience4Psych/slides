<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Large Language Models   ðŸ¤–</title>
    <meta charset="utf-8" />
    <meta name="author" content="S. Mason Garrison" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="../slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Introduction to Large Language Models <br> <code>ðŸ¤–</code>
]
.author[
### S. Mason Garrison
]

---







layout: true
  
&lt;div class="my-footer"&gt;
&lt;span&gt;
&lt;a href="https://DataScience4Psych.github.io/DataScience4Psych/" target="_blank"&gt;Data Science for Psychologists&lt;/a&gt;
&lt;/span&gt;
&lt;/div&gt; 

---





class: middle
# Getting Started with Large Language Models

---

## What are Large Language Models?

.pull-left[
- Large Language Models (LLMs) 
  - are a type of artificial intelligence designed to 
    - understand and 
    - generate human language. 
- These advanced AI systems are trained on *vast* amounts of text data.
]

--

.pull-right[
Key characteristics:

- Massive scale (billions of parameters)
- Self-supervised learning
- Ability to generate human-like text
- Versatile applications and examples
  - GPT (Generative Pre-trained Transformer)
  - BERT (Bidirectional Encoder Representations from Transformers)
  - T5 (Text-to-Text Transfer Transformer)
]

---

# Evolution of LLMs
.question[
How have LLMs evolved over time?
]

&lt;img src="img/chattimeline.png" width="50%" style="display: block; margin: auto;" /&gt;
.footnote[
Image Source: DALL-E: Based on the following prompt: "A visual timeline showcasing the evolution of large language models. The timeline starts from early simple models, progressing through key milestones such as the introduction of transformers, GPT-3, and up to GPT-4. Each milestone is marked with distinct icons and dates, illustrating the increasing complexity and capabilities of these models. The background features a blend of abstract digital patterns representing data and artificial intelligence. The color scheme is professional with shades of blue and gray, with highlighted elements in contrasting colors to emphasize progress."
]

---


# History of LLMs
.pull-left.medi[
## Early models
- Rule-based systems (1960s-1980s)
    - ELIZA: Simple pattern matching with templated responses
    - SHRDLU: Understanding commands through syntax rules
- Statistical models (1990s-2000s)
    - N-grams: Word prediction based on previous few words
    - Hidden Markov Models: Adding probability to language patterns
]
--
.pull-right.medi[
 ## Modern models
  - OpenAIâ€™s LLM ChatGPT (Chat Generative Pre-Trained Transformer) (November 2022)
  - Stanford CRFM and MosaicML's BioMedLM (Biomedical Language Model) (Dec/January 2023)
    - Domain-specific LLMs for biomedical research (trained on PubMed)
  - Meta AI's LLaMA (Large Language Model Meta AI) (Feb 2023)
  - OpenAI's GPT-4 (Generative Pre-trained Transformer) (March 2023)
  - Google's LaMDA (Language Model for Dialogue Applications) (May 2023)
]
.footnote[Alan D. Thompson has a really nice timeline of AI [timelineof AI](https://lifearchitect.ai/timeline/) and [table of models](https://lifearchitect.ai/models-table/)
]

---

class: middle
# How do LLMs work?

---



## The Core Concept: Next-Token Prediction

.pull-left[
**From rules to learning:**
- Early AI: Explicit rules programmed by humans
- Modern LLMs: Learn patterns from data

**The prediction task:**
- Given a sequence of words, predict what comes next
- Example:
  - Input: "The capital of France is"
  - LLM predicts: "Paris" with high confidence
]
--
.pull-right[
**This simple task leads to:**
- Grammar understanding
- Factual knowledge
- Reasoning capabilities
- Context awareness

.question[
How can this single objective (next-word prediction) lead to such versatile abilities?
]
]

---

## How LLMs Process Language

.pull-left[
- LLMs don't process raw text directly
- Text is split into "tokens"
  - Words, subwords, or characters
  - Example: "psychology" â†’ ["psycho", "logy"]
- Different models use different tokenization methods
  - GPT models: Byte-Pair Encoding (BPE)
  - BERT: WordPiece
]

.pull-right[
- Tokens converted to vector representations
- Context window limits how much text can be processed
  - GPT-3.5: ~4,000 tokens
  - GPT-4: 8,000-32,000 tokens
  - Claude: Up to 100,000 tokens
- Models predict tokens based on previous tokens
]

---

# Architecture of LLMs

.pull-left[
Key components:
- **Transformer architecture**
  - Neural network design specialized for sequential data
  - Introduced in "Attention is All You Need" (2017)
  - Processes entire sequences at once, not one-by-one
  - Stacks of identical layers that transform data
- Self-attention mechanism
- Positional encoding
- Layer normalization
- Feed-forward neural networks
]

.pull-right[
&lt;img src="img/transformer.png" width="60%" style="display: block; margin: auto;" /&gt;
]

--

.footnote[
Image Source: DALL-E: Based on the following prompt: "A detailed infographic highlighting the architecture of transformer models. The diagram includes key components such as the encoder, decoder, attention mechanisms, and layers. Arrows indicate the flow of information between these components. The background features a modern design with subtle tech-related patterns. Use professional colors like shades of blue and gray, with important elements highlighted in contrasting colors to draw attention."
]

---



class: middle
# LLM Training Process

---

## LLM Training: Three-Stage Process

.pull-left[
1. **Pre-training**
   - Self-supervised learning on massive text corpus
   - Learns statistical patterns in language

2. **Supervised Fine-Tuning (SFT)**
   - Human-labeled examples of desired outputs
   - Aligns with human instructions

3. **Reinforcement Learning from Human Feedback (RLHF)**
   - Human preferences used to refine model
   - Rewards helpful, truthful, harmless outputs
]

.pull-right[

```
## Error in knitr::include_graphics("img/llm-training-stages.png"): Cannot find the file(s): "img/llm-training-stages.png"
```
]

---

## Pre-training: Learning from Data

.pull-left[
**Training objective:**
- Next token prediction
- Model learns to predict what comes next in a sequence
- Example: "The capital of France is ___" â†’ "Paris"

**Data sources:**
- Books, articles, websites
- Social media, forums
- Code repositories
- Wikipedia
- Scientific literature
]

.pull-right[
**Scale:**
- Hundreds of billions to trillions of tokens
- GPT-3: 300B tokens
- PaLM: 780B tokens
- GPT-4: Estimated trillions of tokens

**Computational requirements:**
- Thousands of GPUs/TPUs
- Weeks to months of training time
- Massive energy consumption
  - GPT-3: ~1,287 MWh (equivalent to 120+ US homes' annual usage)
]

---

## Fine-tuning: Aligning with Human Intent

.pull-left[
**Supervised Fine-Tuning (SFT):**
- Human-written examples of desired outputs
- Model learns to follow instructions
- Much smaller dataset than pre-training
  - Thousands to millions of examples
]

.pull-right[
**Reinforcement Learning from Human Feedback (RLHF):**
1. Generate multiple responses to prompts
2. Human labelers rank responses by quality
3. Train reward model on these preferences
4. Use reinforcement learning to optimize model against reward function

**Result:** More helpful, accurate, and safe outputs
]

---

## Challenges in LLM Training

- **Catastrophic forgetting**
  - Model loses previously learned knowledge during fine-tuning
  - Addressed through careful parameter updates
- **Reward hacking**
  - Model optimizes for reward signals rather than true intentions
  - Requires robust reward modeling
- **Data contamination**
  - Test datasets appearing in training data
  - Inflated benchmark performance
- **Evaluation methods**
  - Perplexity (how well model predicts text)
  - Benchmark datasets (MMLU, HumanEval, TruthfulQA)
  - Human evaluations and red teaming

---

# Applications in Data Science

LLMs can be used for various tasks in data science:

- Text generation and summarization
- Sentiment analysis
- Named Entity Recognition (NER)
- Question answering
- Text classification
- Language translation
---

## Limitations of LLMs

.pull-left[
- **Hallucinations**
  - Generation of plausible but false information
  - Critical concern for research applications
- **Bias**
  - Models inherit biases from training data
  - Can perpetuate stereotypes and inequalities
]
--
.pull-right[
- **Context window limitations**
  - Cannot process unlimited amounts of text
  - May miss important context
- **Computational costs**
  - API usage can be expensive
  - Local deployment requires significant resources
]

---

class: middle

# Ethical Considerations

---

## Ethics and Responsible Use

- **Privacy concerns**
  - Sensitive data in prompts
  - Data retention policies
  - Re-identification risks
- **Academic integrity**
  - Proper attribution
  - Transparency about AI use
  - Maintaining research standards
- **Misinformation risks**
  - Fact-checking importance
  - Critical evaluation of outputs
  - Responsibility in publishing


---

class: middle

# Wrapping Up...

---

# Sources

- Claude Sonnet 3.5. on 07/18/2024
- TBD

---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "ratio": "16:9",
  "highlightLines": true,
  "highlightStyle": "solarized-light",
  "countIncrementalSlides": false,
  "slideNumberFormat": ""
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
